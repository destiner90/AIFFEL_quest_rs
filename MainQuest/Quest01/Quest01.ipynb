{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75068378-2bce-4f82-9c23-d030a3fe2b3f",
   "metadata": {},
   "source": [
    "# **GPT-1 기반 한국어 챗봇 만들기 (수정 버전)**\n",
    "\n",
    "## **변경 사항 요약**\n",
    "이 노트북은 GPT-1 논문의 핵심 개념을 적용하여 수정되었습니다.\n",
    "\n",
    "### **주요 변경 사항:**\n",
    "1. **Transformer 아키텍처 변경**: 기존 Encoder-Decoder → **Decoder-only** 구조로 변경\n",
    "2. **Pre-training 단계 추가**: Unsupervised language modeling objective 사용\n",
    "3. **Fine-tuning 단계 추가**: Task-specific fine-tuning with auxiliary LM objective\n",
    "4. **입력 형식 변경**: GPT 논문의 input transformation 방식 적용\n",
    "5. **학습 방식 변경**: 2-stage training (pre-training → fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9690d053-29a9-465a-9bde-b9502b256b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a5cba8-5301-49ff-b0d6-290e6e021381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import sentencepiece as spm\n",
    "\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b81672e-9b53-4fca-828b-ff54b234fab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.12/site-packages (0.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7f5368-cd35-472a-b961-3ede32ff4462",
   "metadata": {},
   "source": [
    "## **Step 1. 데이터 수집하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a418a522-6612-443f-9c44-ddc70c829651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_to_dataset: /home/jovyan/work/ChatbotData.csv\n"
     ]
    }
   ],
   "source": [
    "path_to_dataset = os.path.join(os.getenv('HOME'), \"work/ChatbotData.csv\")\n",
    "print(\"path_to_dataset:\", path_to_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2605ea26-d10e-43c7-9fad-9b9af9c36f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "MAX_SAMPLES = 50000\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88f26b0c-0c73-48d2-ad5f-5f24d716c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^가-힣0-9?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f1378d8-42a9-404e-88e2-7ff054b235bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chatbotdata_data(path_to_dataset):\n",
    "    with open(path_to_dataset, 'r', errors='ignore') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    pairs = []\n",
    "    for line in lines[1:]:\n",
    "        parts = line.strip().split(\",\")\n",
    "        q_text = preprocess_sentence(parts[0])\n",
    "        a_text = preprocess_sentence(parts[1])\n",
    "        pairs.append((q_text, a_text))\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925e9a41-0fba-4ade-8579-d8c8758a7c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "샘플 예시: ('12시 땡 !', '하루가 또 가네요 .')\n"
     ]
    }
   ],
   "source": [
    "pairs = read_chatbotdata_data(path_to_dataset)\n",
    "print('전체 샘플 수 :', len(pairs))\n",
    "print('샘플 예시:', pairs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984463bd-fb5b-46de-9d2a-cb117dc23b55",
   "metadata": {},
   "source": [
    "## **Step 2. SentencePiece 토크나이저**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e782f49a-5d0e-4434-b0cd-3e24fb92ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/tmp/chatbot_corpus.txt', 'w', encoding='utf-8') as f:\n",
    "    for q, a in pairs:\n",
    "        f.write(q + '\\n')\n",
    "        f.write(a + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d21f8d5a-4cb9-42c7-8c5f-e1dba06d4b06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰 개수: 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=/tmp/chatbot_corpus.txt --model_prefix=chatbot_sp --vocab_size=8000 --model_type=bpe --max_sentence_length=999999 --pad_id=0 --pad_piece=[PAD] --unk_id=1 --unk_piece=[UNK] --bos_id=2 --bos_piece=[BOS] --eos_id=3 --eos_piece=[EOS]\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /tmp/chatbot_corpus.txt\n",
      "  input_format: \n",
      "  model_prefix: chatbot_sp\n",
      "  model_type: BPE\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 999999\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 1\n",
      "  bos_id: 2\n",
      "  eos_id: 3\n",
      "  pad_id: 0\n",
      "  unk_piece: [UNK]\n",
      "  bos_piece: [BOS]\n",
      "  eos_piece: [EOS]\n",
      "  pad_piece: [PAD]\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: /tmp/chatbot_corpus.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 23638 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [PAD]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [UNK]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [BOS]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [EOS]\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=367658\n",
      "trainer_interface.cc(552) LOG(INFO) Done: 99.9505% characters are covered.\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=1054\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=0.999505\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 23638 sentences.\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 23638\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 20572\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13873 min_freq=42\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1047 size=20 all=16058 active=1764 piece=▁거예요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=773 size=40 all=16774 active=2480 piece=▁여\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=619 size=60 all=17435 active=3141 piece=▁좋아하는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=424 size=80 all=18038 active=3744 piece=▁한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=357 size=100 all=18765 active=4471 piece=▁전\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=351 min_freq=37\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=307 size=120 all=19198 active=1399 piece=▁뭐\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=262 size=140 all=19794 active=1995 piece=▁진\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=227 size=160 all=20215 active=2416 piece=▁비\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=206 size=180 all=20571 active=2772 piece=▁행\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=188 size=200 all=20940 active=3141 piece=▁관\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=187 min_freq=31\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=172 size=220 all=21293 active=1393 piece=▁재\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=155 size=240 all=21610 active=1710 piece=▁따\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=144 size=260 all=21938 active=2038 piece=▁자꾸\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=136 size=280 all=22319 active=2419 piece=▁고백\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=130 size=300 all=22669 active=2769 piece=▁먼저\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=130 min_freq=26\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=121 size=320 all=22993 active=1453 piece=▁직\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=115 size=340 all=23332 active=1792 piece=▁버\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=108 size=360 all=23548 active=2008 piece=▁돈\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=103 size=380 all=23857 active=2317 piece=▁세\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=99 size=400 all=24253 active=2713 piece=▁싫어\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=99 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=91 size=420 all=24558 active=1506 piece=���인\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=87 size=440 all=24843 active=1791 piece=▁무슨\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=84 size=460 all=24999 active=1947 piece=▁최\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=480 all=25311 active=2259 piece=▁힘드네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=77 size=500 all=25547 active=2495 piece=▁많아\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=77 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74 size=520 all=25772 active=1497 piece=▁부담\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=71 size=540 all=26014 active=1739 piece=▁타는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=560 all=26294 active=2019 piece=▁만큼\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=580 all=26478 active=2203 piece=▁때문\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=63 size=600 all=26624 active=2349 piece=▁항\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=63 min_freq=18\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62 size=620 all=26778 active=1485 piece=▁아파\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=640 all=27044 active=1751 piece=하네요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=660 all=27315 active=2022 piece=▁천\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=680 all=27517 active=2224 piece=▁다음\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53 size=700 all=27642 active=2349 piece=▁그렇\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=53 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=720 all=27759 active=1486 piece=걸까\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=50 size=740 all=27937 active=1664 piece=▁아침\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=760 all=28073 active=1800 piece=▁언젠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=780 all=28203 active=1930 piece=▁된\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47 size=800 all=28319 active=2046 piece=▁있나봐요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=46 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=820 all=28416 active=1513 piece=▁못하\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=840 all=28605 active=1702 piece=한지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=860 all=28740 active=1837 piece=▁주말\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=880 all=28814 active=1911 piece=▁모르는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=900 all=28921 active=2018 piece=▁좋아할\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=41 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=920 all=29037 active=1559 piece=같은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=940 all=29213 active=1735 piece=▁흐\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=960 all=29385 active=1907 piece=▁모르겠어요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=980 all=29557 active=2079 piece=▁오늘은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=1000 all=29688 active=2210 piece=▁솔직\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=36 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=1020 all=29845 active=1630 piece=▁것이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=1040 all=29982 active=1767 piece=주는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=1060 all=30099 active=1884 piece=▁책\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=1080 all=30218 active=2003 piece=▁멀\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=1100 all=30332 active=2117 piece=▁뿐이에요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=32 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=1120 all=30436 active=1621 piece=▁스타\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=1140 all=30509 active=1694 piece=▁자존\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=1160 all=30630 active=1815 piece=▁나오\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=1180 all=30723 active=1908 piece=▁이상형\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=1200 all=30830 active=2015 piece=▁보면\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=28 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=1220 all=30880 active=1592 piece=▁주무세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=1240 all=30988 active=1700 piece=▁나중에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=1260 all=31043 active=1755 piece=▁쓸\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=1280 all=31117 active=1829 piece=▁중에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=1300 all=31185 active=1897 piece=▁친구한테\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=26 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=1320 all=31360 active=1734 piece=▁대로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=1340 all=31406 active=1780 piece=▁편이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=1360 all=31437 active=1811 piece=기만\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=1380 all=31546 active=1920 piece=▁이번\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=1400 all=31610 active=1984 piece=▁사랑하고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=1420 all=31701 active=1671 piece=▁스킨\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=1440 all=31805 active=1775 piece=▁이제는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1460 all=31855 active=1825 piece=▁뭔지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=1480 all=31917 active=1887 piece=▁가슴이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1500 all=31971 active=1941 piece=▁택\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=21 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1520 all=32106 active=1732 piece=▁볼까\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=1540 all=32169 active=1795 piece=▁방법이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1560 all=32229 active=1855 piece=▁클\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1580 all=32369 active=1995 piece=▁떨려\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1600 all=32437 active=2063 piece=▁꾸준히\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=20 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=1620 all=32445 active=1630 piece=▁진심으로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1640 all=32529 active=1714 piece=▁대학\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1660 all=32620 active=1805 piece=▁집안\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=1680 all=32673 active=1858 piece=▁준비가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1700 all=32709 active=1894 piece=▁팔\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1720 all=32847 active=1763 piece=▁놀이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1740 all=32916 active=1832 piece=▁착각\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=1760 all=32965 active=1881 piece=▁하나도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1780 all=33012 active=1928 piece=성이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1800 all=33118 active=2034 piece=▁바빠\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1820 all=33179 active=1715 piece=으면서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=1840 all=33211 active=1747 piece=▁생각하세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1860 all=33310 active=1846 piece=이다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1880 all=33381 active=1917 piece=▁배고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1900 all=33444 active=1980 piece=▁지쳐\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=1920 all=33479 active=1702 piece=▁괜찮아졌\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1940 all=33495 active=1718 piece=▁뒷\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1960 all=33614 active=1837 piece=▁거절\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=1980 all=33670 active=1893 piece=���신혼\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=2000 all=33750 active=1973 piece=▁내일은\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=2020 all=33750 active=1688 piece=▁호감을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2040 all=33766 active=1704 piece=▁썼\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2060 all=33905 active=1843 piece=할지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2080 all=33962 active=1900 piece=▁불러\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2100 all=34008 active=1946 piece=으려고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2120 all=34023 active=1707 piece=▁얼마나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=2140 all=34010 active=1694 piece=▁필요하죠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2160 all=34014 active=1698 piece=▁움\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2180 all=34140 active=1824 piece=준비\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2200 all=34211 active=1895 piece=▁만드\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2220 all=34267 active=1763 piece=▁알았\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2240 all=34335 active=1831 piece=▁크게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2260 all=34392 active=1888 piece=▁먹을까\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2280 all=34393 active=1889 piece=▁있는게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=2300 all=34415 active=1911 piece=▁버리세요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2320 all=34413 active=1719 piece=▁넣\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2340 all=34509 active=1815 piece=해줄\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2360 all=34547 active=1853 piece=▁마다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2380 all=34584 active=1890 piece=▁이게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2400 all=34624 active=1930 piece=버렸어\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2420 all=34649 active=1749 piece=▁선물이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2440 all=34637 active=1737 piece=▁하면서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=2460 all=34624 active=1724 piece=▁충분해요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2480 all=34624 active=1724 piece=▁맥\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2500 all=34701 active=1801 piece=시면\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2520 all=34782 active=1812 piece=▁것은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2540 all=34803 active=1833 piece=▁만족\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2560 all=34845 active=1875 piece=▁쓸데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2580 all=34897 active=1927 piece=▁최악\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2600 all=34952 active=1982 piece=▁나이는\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2620 all=34957 active=1753 piece=▁선물을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2640 all=34953 active=1749 piece=이었으면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=2660 all=34950 active=1746 piece=▁하셨네요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2680 all=34962 active=1758 piece=▁뽑\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2700 all=35031 active=1827 piece=순위\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2720 all=35104 active=1819 piece=▁과식\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2740 all=35136 active=1851 piece=▁모아\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2760 all=35180 active=1895 piece=▁오네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2780 all=35214 active=1929 piece=▁헬스\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2800 all=35280 active=1995 piece=▁남자랑\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2820 all=35281 active=1765 piece=▁세상에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2840 all=35267 active=1751 piece=▁전화를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2860 all=35281 active=1765 piece=▁만들어요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=2880 all=35271 active=1755 piece=▁남자친구랑\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2900 all=35286 active=1770 piece=▁닮\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2920 all=35354 active=1829 piece=라이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2940 all=35471 active=1946 piece=테리\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2960 all=35516 active=1991 piece=▁늦은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=2980 all=35544 active=2019 piece=▁봄이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3000 all=35563 active=2038 piece=▁없지\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3020 all=35587 active=1803 piece=▁핑계\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3040 all=35659 active=1875 piece=하기도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3060 all=35679 active=1895 piece=▁달라진\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3080 all=35669 active=1885 piece=▁솔직한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3100 all=35660 active=1876 piece=▁이제야\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3120 all=35652 active=1775 piece=▁헤어질\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3140 all=35644 active=1767 piece=▁슬프네요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3160 all=35638 active=1761 piece=▁헤어졌네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3180 all=35628 active=1751 piece=▁조��이라도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3200 all=35643 active=1766 piece=▁효\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3220 all=35707 active=1843 piece=육아\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3240 all=35758 active=1894 piece=▁그립\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3260 all=35786 active=1922 piece=▁멀리\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3280 all=35823 active=1959 piece=▁수는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3300 all=35855 active=1991 piece=▁웬수\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3320 all=35877 active=1812 piece=▁참견\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3340 all=35918 active=1853 piece=가는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3360 all=36002 active=1937 piece=▁가족이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3380 all=35994 active=1929 piece=▁눈치가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3400 all=35987 active=1922 piece=▁모르게\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3420 all=35978 active=1791 piece=▁아까워\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3440 all=35977 active=1790 piece=▁전화가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3460 all=35990 active=1803 piece=▁결혼해도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3480 all=35973 active=1786 piece=▁세상에서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3500 all=35971 active=1784 piece=▁헤아리는\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=3520 all=35955 active=1783 piece=▁좋아하는거\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3540 all=35954 active=1782 piece=▁며\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3560 all=36008 active=1836 piece=나나\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3580 all=36063 active=1891 piece=셔야\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3600 all=36124 active=1952 piece=침표\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3620 all=36140 active=1820 piece=▁길어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3640 all=36153 active=1833 piece=▁동성\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3660 all=36177 active=1857 piece=▁사내\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3680 all=36200 active=1880 piece=▁오지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3700 all=36206 active=1886 piece=▁줄어\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3720 all=36240 active=1842 piece=▁확신\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3740 all=36303 active=1905 piece=했지만\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3760 all=36293 active=1895 piece=▁다음에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3780 all=36278 active=1880 piece=▁모든걸\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3800 all=36279 active=1881 piece=▁소리가\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3820 all=36266 active=1801 piece=▁여자는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3840 all=36268 active=1803 piece=▁정말로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3860 all=36262 active=1797 piece=▁해주고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3880 all=36262 active=1797 piece=▁모르는게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3900 all=36248 active=1783 piece=▁안되는데\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3920 all=36239 active=1804 piece=▁하루에도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3940 all=36221 active=1786 piece=▁버텨보세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7 size=3960 all=36207 active=1772 piece=▁필요하겠어요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=3980 all=36226 active=1791 piece=▁액\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4000 all=36278 active=1843 piece=끄러\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4020 all=36335 active=1867 piece=상은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4040 all=36395 active=1927 piece=질방\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4060 all=36445 active=1977 piece=▁갈때\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4080 all=36452 active=1984 piece=▁꾸며\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4100 all=36479 active=2011 piece=▁들리\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4120 all=36494 active=1837 piece=▁무릎\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4140 all=36509 active=1852 piece=▁소액\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4160 all=36519 active=1862 piece=▁아님\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4180 all=36533 active=1876 piece=▁왕따\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4200 all=36547 active=1890 piece=▁자취\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4220 all=36566 active=1843 piece=▁차갑\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4240 all=36596 active=1873 piece=▁평온\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4260 all=36617 active=1894 piece=년만에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4280 all=36672 active=1949 piece=적이고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4300 all=36699 active=1976 piece=▁것들이\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4320 all=36687 active=1823 piece=▁길에서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4340 all=36675 active=1811 piece=▁드시고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4360 all=36665 active=1801 piece=▁문제로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4380 all=36654 active=1790 piece=▁생리통\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4400 all=36641 active=1777 piece=▁않지만\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4420 all=36627 active=1819 piece=▁이해할\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4440 all=36622 active=1814 piece=▁집착해\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4460 all=36615 active=1807 piece=▁하루가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4480 all=36620 active=1812 piece=▁공부하기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4500 all=36607 active=1799 piece=▁매일매일\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4520 all=36597 active=1821 piece=▁신경쓰는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4540 all=36589 active=1813 piece=▁좋습니다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4560 all=36579 active=1803 piece=▁행복할까\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4580 all=36568 active=1792 piece=▁상관없어요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4600 all=36549 active=1773 piece=▁줄여보세요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6 size=4620 all=36532 active=1811 piece=▁좋아할거예요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4640 all=36542 active=1821 piece=▁승\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4660 all=36580 active=1859 piece=나가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4680 all=36620 active=1899 piece=문이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4700 all=36681 active=1960 piece=와의\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4720 all=36736 active=1887 piece=진다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4740 all=36766 active=1917 piece=▁거는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4760 all=36775 active=1926 piece=▁끓여\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4780 all=36788 active=1939 piece=▁답은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4800 all=36782 active=1933 piece=▁모임\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4820 all=36794 active=1848 piece=▁벽에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4840 all=36803 active=1857 piece=▁세월\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4860 all=36822 active=1876 piece=▁알지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4880 all=36837 active=1891 piece=▁일반\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4900 all=36856 active=1910 piece=▁진행\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=4\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4920 all=36873 active=1858 piece=▁틀린\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4940 all=36901 active=1886 piece=년연애\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4960 all=36946 active=1931 piece=하겠지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=4980 all=36955 active=1940 piece=▁금수저\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5000 all=36952 active=1937 piece=▁대화로\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5020 all=36944 active=1840 piece=▁만남에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5040 all=36938 active=1834 piece=▁믿음을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5060 all=36925 active=1821 piece=▁사겨도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5080 all=36915 active=1811 piece=▁싶다는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5100 all=36908 active=1804 piece=▁예민한\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5120 all=36898 active=1835 piece=▁좋을지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5140 all=36889 active=1826 piece=▁친구와\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5160 all=36879 active=1816 piece=▁해보고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5180 all=36895 active=1832 piece=▁가능하면\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5200 all=36878 active=1815 piece=▁들어왔어\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5220 all=36863 active=1829 piece=▁사랑해요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5240 all=36852 active=1818 piece=▁알콩달콩\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5260 all=36838 active=1804 piece=▁일어나는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5280 all=36823 active=1789 piece=▁중요한데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5300 all=36811 active=1777 piece=었으니까요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5320 all=36797 active=1824 piece=▁사과하세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5 size=5340 all=36778 active=1805 piece=▁좋을텐데요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5360 all=36766 active=1793 piece=▁국\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5380 all=36787 active=1814 piece=▁씹\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5400 all=36805 active=1832 piece=가능\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5420 all=36844 active=1874 piece=났네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5440 all=36880 active=1910 piece=리죠\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5460 all=36904 active=1934 piece=생각\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5480 all=36944 active=1974 piece=였네\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5500 all=36985 active=2015 piece=지우\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5520 all=37023 active=1882 piece=함에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5540 all=37034 active=1893 piece=▁걷길\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5560 all=37037 active=1896 piece=▁꾹꾹\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5580 all=37034 active=1893 piece=▁놔둬\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5600 all=37036 active=1895 piece=▁드릴\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5620 all=37031 active=1846 piece=▁먹은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5640 all=37039 active=1854 piece=▁바꿨\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5660 all=37052 active=1867 piece=▁부질\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5680 all=37078 active=1893 piece=▁설득\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5700 all=37090 active=1905 piece=▁안될\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5720 all=37096 active=1860 piece=▁오길\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5740 all=37096 active=1860 piece=▁음료\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5760 all=37112 active=1876 piece=▁적당\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5780 all=37124 active=1888 piece=▁지낸\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5800 all=37139 active=1903 piece=▁최저\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5820 all=37143 active=1860 piece=▁팍팍\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5840 all=37148 active=1865 piece=▁현타\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5860 all=37163 active=1880 piece=렵니다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5880 all=37198 active=1915 piece=하기로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5900 all=37223 active=1940 piece=▁가족들\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5920 all=37209 active=1847 piece=▁고양이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5940 all=37193 active=1831 piece=▁기억해\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5960 all=37184 active=1822 piece=▁노래는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=5980 all=37170 active=1808 piece=▁되어요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6000 all=37161 active=1799 piece=▁막히는\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6020 all=37151 active=1849 piece=▁먹는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6040 all=37137 active=1835 piece=▁발전이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6060 all=37124 active=1822 piece=▁불편한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6080 all=37110 active=1808 piece=▁선택이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6100 all=37105 active=1803 piece=▁시선을\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6120 all=37090 active=1841 piece=▁아이디\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6140 all=37082 active=1833 piece=▁어디든\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6160 all=37069 active=1820 piece=▁예민해\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6180 all=37055 active=1806 piece=▁유부녀\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6200 all=37050 active=1801 piece=▁잇몸약\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6220 all=37044 active=1847 piece=▁전하지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6240 all=37030 active=1833 piece=▁즐겁게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6260 all=37014 active=1817 piece=▁커피가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6280 all=36997 active=1800 piece=▁할까요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6300 all=36984 active=1787 piece=기만해도\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6320 all=37009 active=1872 piece=▁가리세요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6340 all=37001 active=1864 piece=▁과식하지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6360 all=36985 active=1848 piece=▁남친이랑\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6380 all=36967 active=1830 piece=▁동생한테\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6400 all=36948 active=1811 piece=▁무한리필\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6420 all=36937 active=1836 piece=▁뿌린대로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6440 all=36920 active=1819 piece=▁쉬어가도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6460 all=36904 active=1803 piece=▁안해먹고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6480 all=36887 active=1786 piece=▁염탐하지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6500 all=36869 active=1768 piece=▁이해하고\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6520 all=36856 active=1831 piece=▁존중하고\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6540 all=36838 active=1813 piece=▁친구인데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6560 all=36822 active=1797 piece=▁해봤는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6580 all=36813 active=1788 piece=▁가족들이랑\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6600 all=36797 active=1772 piece=▁놀러가세요\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6620 all=36777 active=1820 piece=▁받아들여야\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6640 all=36760 active=1803 piece=▁성공적으로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6660 all=36740 active=1783 piece=▁연락이라도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6680 all=36721 active=1764 piece=▁점심시간에\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6700 all=36704 active=1747 piece=▁포장하는게\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6720 all=36686 active=1818 piece=▁대단하시군요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4 size=6740 all=36666 active=1798 piece=▁피곤했나봐요\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6760 all=36660 active=1792 piece=▁꿔\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6780 all=36675 active=1807 piece=▁뻐\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6800 all=36687 active=1819 piece=▁텅\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=3\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6820 all=36702 active=1849 piece=걸이\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6840 all=36728 active=1875 piece=꾸던\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6860 all=36750 active=1897 piece=독여\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6880 all=36777 active=1924 piece=르몬\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6900 all=36809 active=1956 piece=보려\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3 min_freq=2\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6920 all=36851 active=1879 piece=소짓\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=6940 all=36880 active=1908 piece=었나\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: chatbot_sp.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: chatbot_sp.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input=/tmp/chatbot_corpus.txt '\n",
    "    '--model_prefix=chatbot_sp '\n",
    "    '--vocab_size=8000 '\n",
    "    '--model_type=bpe '\n",
    "    '--max_sentence_length=999999 '\n",
    "    '--pad_id=0 --pad_piece=[PAD] '\n",
    "    '--unk_id=1 --unk_piece=[UNK] '\n",
    "    '--bos_id=2 --bos_piece=[BOS] '\n",
    "    '--eos_id=3 --eos_piece=[EOS]'\n",
    ")\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('chatbot_sp.model')\n",
    "print(f\"토큰 개수: {sp.GetPieceSize()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new_section_1",
   "metadata": {},
   "source": [
    "## **Step 3. GPT-1 모델 구현**\n",
    "\n",
    "### **🔴 [변경] Decoder-only Transformer 구조**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "gpt1_decoder_block",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔴 [변경] GPT-1 스타일 Decoder Block\n",
    "class GPT1DecoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    GPT-1 논문의 Transformer Decoder Block\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super(GPT1DecoderBlock, self).__init__()\n",
    "        \n",
    "        # Masked Self-Attention\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Feed-Forward Network\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU(),  # 🔴 [변경] GPT-1은 GELU 활성화 함수 사용\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, attn_mask=None, key_padding_mask=None):\n",
    "        # Self-Attention with residual connection\n",
    "        attn_output, _ = self.self_attn(\n",
    "            x, x, x, \n",
    "            attn_mask=attn_mask,\n",
    "            key_padding_mask=key_padding_mask\n",
    "        )\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Feed-Forward with residual connection\n",
    "        ffn_output = self.ffn(x)\n",
    "        x = self.norm2(x + ffn_output)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "gpt1_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔴 [변경] GPT-1 Decoder-only 모델 (NaN 문제 해결)\n",
    "class GPT1Model(nn.Module):\n",
    "    \"\"\"\n",
    "    GPT-1 스타일의 Decoder-only Language Model\n",
    "    \n",
    "    🔧 NaN 문제 해결:\n",
    "    - Position embedding 초기화 개선\n",
    "    - Padding mask 계산 수정\n",
    "    - 안정적인 forward pass\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model=512, num_heads=8, num_layers=6, \n",
    "                 d_ff=2048, max_len=512, dropout=0.1, pad_idx=0):\n",
    "        super(GPT1Model, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        # Token Embedding\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model, padding_idx=pad_idx)\n",
    "        \n",
    "        # 🔴 [변경] GPT-1은 학습 가능한 Position Embedding 사용\n",
    "        self.position_embedding = nn.Embedding(max_len, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Decoder Blocks\n",
    "        self.decoder_blocks = nn.ModuleList([\n",
    "            GPT1DecoderBlock(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Final layer norm\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_projection = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "        # 🔧 [수정] Weight initialization 개선\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"🔧 [수정] 안정적인 weight initialization\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "                # 🔧 [수정] Padding idx는 0으로 초기화\n",
    "                if module.padding_idx is not None:\n",
    "                    module.weight.data[module.padding_idx].zero_()\n",
    "            elif isinstance(module, nn.LayerNorm):\n",
    "                module.bias.data.zero_()\n",
    "                module.weight.data.fill_(1.0)\n",
    "    \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        \"\"\"Causal mask for autoregressive generation\"\"\"\n",
    "        mask = torch.triu(torch.ones(sz, sz), diagonal=1).bool()\n",
    "        return mask\n",
    "    \n",
    "    def forward(self, x, targets=None):\n",
    "        \"\"\"\n",
    "        🔧 [수정] 안정적인 forward pass\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.size()\n",
    "        device = x.device\n",
    "        \n",
    "        # Create position indices\n",
    "        positions = torch.arange(0, seq_len, dtype=torch.long, device=device)\n",
    "        positions = positions.unsqueeze(0).expand(batch_size, seq_len)\n",
    "        \n",
    "        # Token + Position Embeddings\n",
    "        token_emb = self.token_embedding(x)  # [batch, seq_len, d_model]\n",
    "        pos_emb = self.position_embedding(positions)  # [batch, seq_len, d_model]\n",
    "        x = self.dropout(token_emb + pos_emb)\n",
    "        \n",
    "        # Create causal mask\n",
    "        attn_mask = self.generate_square_subsequent_mask(seq_len).to(device)\n",
    "        \n",
    "        # 🔧 [수정] Padding mask 계산 개선\n",
    "        # input의 실제 token id를 기반으로 padding 여부 판단\n",
    "        key_padding_mask = (x.sum(dim=-1) == 0)  # [batch_size, seq_len]\n",
    "        \n",
    "        # Apply decoder blocks\n",
    "        for decoder_block in self.decoder_blocks:\n",
    "            x = decoder_block(x, attn_mask=attn_mask, key_padding_mask=key_padding_mask)\n",
    "        \n",
    "        # Final normalization and projection\n",
    "        x = self.norm(x)\n",
    "        logits = self.output_projection(x)\n",
    "        \n",
    "        # 🔧 [수정] 안정적인 loss 계산\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            # Flatten for loss calculation\n",
    "            logits_flat = logits.view(-1, logits.size(-1))\n",
    "            targets_flat = targets.view(-1)\n",
    "            \n",
    "            # Calculate loss with ignore_index for padding\n",
    "            loss = F.cross_entropy(\n",
    "                logits_flat,\n",
    "                targets_flat,\n",
    "                ignore_index=self.pad_idx,\n",
    "                reduction='mean'\n",
    "            )\n",
    "            \n",
    "            # 🔧 [추가] NaN 체크\n",
    "            if torch.isnan(loss):\n",
    "                print(\"Warning: NaN loss detected!\")\n",
    "                # 디버깅 정보 출력\n",
    "                print(f\"Logits: min={logits_flat.min():.4f}, max={logits_flat.max():.4f}\")\n",
    "                print(f\"Targets: min={targets_flat.min()}, max={targets_flat.max()}\")\n",
    "        \n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset_section",
   "metadata": {},
   "source": [
    "## **Step 4. Dataset 구성**\n",
    "\n",
    "### **🔴 [변경] GPT-1 스타일 입력 형식**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "gpt1_dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔴 [변경] GPT-1 스타일 Dataset (수정 버전)\n",
    "class GPT1ChatDataset(Dataset):\n",
    "    \"\"\"\n",
    "    GPT-1 논문의 입력 형식\n",
    "    형식: [BOS] question $ answer [EOS]\n",
    "    \n",
    "    🔧 [수정] 안정적인 토큰화\n",
    "    \"\"\"\n",
    "    def __init__(self, pairs, sp, max_len=64):\n",
    "        self.pairs = pairs\n",
    "        self.sp = sp\n",
    "        self.max_len = max_len\n",
    "        self.bos_id = sp.bos_id()\n",
    "        self.eos_id = sp.eos_id()\n",
    "        self.pad_id = sp.pad_id()\n",
    "\n",
    "        # 🔴 [추가] Delimiter token for GPT-1 style input\n",
    "        self.delim_id = sp.piece_to_id('$') if sp.piece_to_id('$') != sp.unk_id() else sp.unk_id()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        question, answer = self.pairs[idx]\n",
    "        \n",
    "        # Tokenize\n",
    "        q_tokens = self.sp.encode_as_ids(question)\n",
    "        a_tokens = self.sp.encode_as_ids(answer)\n",
    "        \n",
    "        # 🔴 [변경] GPT-1 input format: [BOS] Q $ A [EOS]\n",
    "        input_ids = [self.bos_id] + q_tokens + [self.delim_id] + a_tokens + [self.eos_id]\n",
    "        \n",
    "        # Truncate if too long\n",
    "        if len(input_ids) > self.max_len:\n",
    "            input_ids = input_ids[:self.max_len]\n",
    "            input_ids[-1] = self.eos_id\n",
    "        \n",
    "        # 🔧 [수정] Target은 input을 1칸 shift\n",
    "        target_ids = input_ids[1:] + [self.pad_id]\n",
    "        \n",
    "        # Padding\n",
    "        padding_len = self.max_len - len(input_ids)\n",
    "        input_ids = input_ids + [self.pad_id] * padding_len\n",
    "        target_ids = target_ids + [self.pad_id] * padding_len\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(target_ids, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "create_dataset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 크기: 11823\n",
      "Batch 수: 370\n",
      "\n",
      "입력 토큰: tensor([   2, 5527, 6988, 3193,  104,    1, 4463,  215, 5897,    4,    3,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0])\n",
      "타겟 토큰: tensor([5527, 6988, 3193,  104,    1, 4463,  215, 5897,    4,    3,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "# Dataset 생성\n",
    "dataset = GPT1ChatDataset(pairs[:MAX_SAMPLES], sp, max_len=64)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Dataset 크기: {len(dataset)}\")\n",
    "print(f\"Batch 수: {len(dataloader)}\")\n",
    "\n",
    "# 샘플 확인\n",
    "sample = dataset[0]\n",
    "print(\"\\n입력 토큰:\", sample['input_ids'][:20])\n",
    "print(\"타겟 토큰:\", sample['targets'][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training_section",
   "metadata": {},
   "source": [
    "## **Step 5. 학습**\n",
    "\n",
    "### **🔧 [수정] 안정적인 학습 함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "train_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gpt1(model, dataloader, optimizer, scheduler, num_epochs, device):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        total_tokens = 0\n",
    "        \n",
    "        for step, batch in enumerate(dataloader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            targets = batch['targets'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            logits, loss = model(input_ids, targets)\n",
    "            \n",
    "            # 🔧 [추가] NaN 체크\n",
    "            if torch.isnan(loss):\n",
    "                print(f\"NaN detected at epoch {epoch+1}, step {step}. Skipping batch.\")\n",
    "                continue\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # 🔧 [수정] Gradient clipping 강화\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            with torch.no_grad():\n",
    "                predictions = logits.argmax(dim=-1)\n",
    "                mask = (targets != model.pad_idx)\n",
    "                correct = ((predictions == targets) & mask).sum().item()\n",
    "                num_tokens = mask.sum().item()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                total_correct += correct\n",
    "                total_tokens += num_tokens\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                acc = correct / num_tokens if num_tokens > 0 else 0\n",
    "                print(f\"[Epoch {epoch+1}, Step {step}] Loss: {loss.item():.4f}, Acc: {acc:.4f}\")\n",
    "        \n",
    "        # Epoch 종료\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_acc = total_correct / total_tokens if total_tokens > 0 else 0\n",
    "        print(f\"Epoch {epoch+1} Completed - Avg Loss: {avg_loss:.4f}, Avg Acc: {avg_acc:.4f}\")\n",
    "        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "model_init",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 파라미터 수: 7,279,936\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "vocab_size = sp.GetPieceSize()\n",
    "\n",
    "# 🔴 [변경] GPT-1 모델 파라미터\n",
    "model = GPT1Model(\n",
    "    vocab_size=vocab_size,\n",
    "    d_model=256,      \n",
    "    num_heads=8,\n",
    "    num_layers=4,     \n",
    "    d_ff=1024,        \n",
    "    max_len=64,\n",
    "    dropout=0.1,\n",
    "    pad_idx=sp.pad_id()\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"모델 파라미터 수: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4099255-cfc2-45b5-95e1-2dd81a449277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT1Model(\n",
      "  (token_embedding): Embedding(8000, 256, padding_idx=0)\n",
      "  (position_embedding): Embedding(64, 256)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (decoder_blocks): ModuleList(\n",
      "    (0-3): 4 x GPT1DecoderBlock(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (4): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (output_projection): Linear(in_features=256, out_features=8000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "optimizer_init",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer 설정 완료\n"
     ]
    }
   ],
   "source": [
    "# 🔧 [수정] 안정적인 optimizer 설정\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,          # 🔧 [수정] learning rate 낮춤\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0.01  # 🔧 [추가] weight decay\n",
    ")\n",
    "\n",
    "# 🔧 [수정] Learning rate scheduler\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=40,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "print(\"Optimizer 설정 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "training_execution",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Step 0] Loss: 9.0116, Acc: 0.0000\n",
      "[Epoch 1, Step 100] Loss: 7.5953, Acc: 0.1945\n",
      "[Epoch 1, Step 200] Loss: 6.7783, Acc: 0.2179\n",
      "[Epoch 1, Step 300] Loss: 6.7539, Acc: 0.2117\n",
      "Epoch 1 Completed - Avg Loss: 7.1695, Avg Acc: 0.1973\n",
      "Learning Rate: 0.000100\n",
      "[Epoch 2, Step 0] Loss: 6.6416, Acc: 0.2030\n",
      "[Epoch 2, Step 100] Loss: 6.5433, Acc: 0.2116\n",
      "[Epoch 2, Step 200] Loss: 6.2570, Acc: 0.2279\n",
      "[Epoch 2, Step 300] Loss: 6.3126, Acc: 0.2204\n",
      "Epoch 2 Completed - Avg Loss: 6.3375, Avg Acc: 0.2252\n",
      "Learning Rate: 0.000099\n",
      "[Epoch 3, Step 0] Loss: 6.2444, Acc: 0.2348\n",
      "[Epoch 3, Step 100] Loss: 6.1228, Acc: 0.2480\n",
      "[Epoch 3, Step 200] Loss: 6.3025, Acc: 0.2265\n",
      "[Epoch 3, Step 300] Loss: 6.0840, Acc: 0.2410\n",
      "Epoch 3 Completed - Avg Loss: 6.2869, Avg Acc: 0.2296\n",
      "Learning Rate: 0.000099\n",
      "[Epoch 4, Step 0] Loss: 6.2284, Acc: 0.2326\n",
      "[Epoch 4, Step 100] Loss: 6.4357, Acc: 0.2190\n",
      "[Epoch 4, Step 200] Loss: 6.2910, Acc: 0.2293\n",
      "[Epoch 4, Step 300] Loss: 6.2318, Acc: 0.2525\n",
      "Epoch 4 Completed - Avg Loss: 6.3716, Avg Acc: 0.2279\n",
      "Learning Rate: 0.000098\n",
      "[Epoch 5, Step 0] Loss: 6.2747, Acc: 0.2512\n",
      "[Epoch 5, Step 100] Loss: 6.3578, Acc: 0.2451\n",
      "[Epoch 5, Step 200] Loss: 6.3833, Acc: 0.2215\n",
      "[Epoch 5, Step 300] Loss: 6.4269, Acc: 0.2469\n",
      "Epoch 5 Completed - Avg Loss: 6.4493, Avg Acc: 0.2296\n",
      "Learning Rate: 0.000096\n",
      "[Epoch 6, Step 0] Loss: 6.5394, Acc: 0.2149\n",
      "[Epoch 6, Step 100] Loss: 6.6742, Acc: 0.2103\n",
      "[Epoch 6, Step 200] Loss: 6.4887, Acc: 0.2513\n",
      "[Epoch 6, Step 300] Loss: 6.7850, Acc: 0.2018\n",
      "Epoch 6 Completed - Avg Loss: 6.5276, Avg Acc: 0.2271\n",
      "Learning Rate: 0.000095\n",
      "[Epoch 7, Step 0] Loss: 6.7525, Acc: 0.2045\n",
      "[Epoch 7, Step 100] Loss: 6.7045, Acc: 0.2158\n",
      "[Epoch 7, Step 200] Loss: 6.7090, Acc: 0.2075\n",
      "[Epoch 7, Step 300] Loss: 6.4722, Acc: 0.2290\n",
      "Epoch 7 Completed - Avg Loss: 6.5734, Avg Acc: 0.2250\n",
      "Learning Rate: 0.000093\n",
      "[Epoch 8, Step 0] Loss: 6.4662, Acc: 0.2244\n",
      "[Epoch 8, Step 100] Loss: 6.4445, Acc: 0.2415\n",
      "[Epoch 8, Step 200] Loss: 6.6810, Acc: 0.2043\n",
      "[Epoch 8, Step 300] Loss: 6.3750, Acc: 0.2376\n",
      "Epoch 8 Completed - Avg Loss: 6.5987, Avg Acc: 0.2239\n",
      "Learning Rate: 0.000091\n",
      "[Epoch 9, Step 0] Loss: 6.6169, Acc: 0.2311\n",
      "[Epoch 9, Step 100] Loss: 6.4797, Acc: 0.2526\n",
      "[Epoch 9, Step 200] Loss: 6.7526, Acc: 0.2089\n",
      "[Epoch 9, Step 300] Loss: 6.8623, Acc: 0.1929\n",
      "Epoch 9 Completed - Avg Loss: 6.6231, Avg Acc: 0.2239\n",
      "Learning Rate: 0.000088\n",
      "[Epoch 10, Step 0] Loss: 6.7334, Acc: 0.2111\n",
      "[Epoch 10, Step 100] Loss: 6.4385, Acc: 0.2382\n",
      "[Epoch 10, Step 200] Loss: 6.6989, Acc: 0.2102\n",
      "[Epoch 10, Step 300] Loss: 6.6059, Acc: 0.2304\n",
      "Epoch 10 Completed - Avg Loss: 6.6389, Avg Acc: 0.2235\n",
      "Learning Rate: 0.000086\n",
      "[Epoch 11, Step 0] Loss: 6.7423, Acc: 0.2123\n",
      "[Epoch 11, Step 100] Loss: 6.7919, Acc: 0.2106\n",
      "[Epoch 11, Step 200] Loss: 6.7052, Acc: 0.2281\n",
      "[Epoch 11, Step 300] Loss: 6.6194, Acc: 0.2293\n",
      "Epoch 11 Completed - Avg Loss: 6.6606, Avg Acc: 0.2232\n",
      "Learning Rate: 0.000083\n",
      "[Epoch 12, Step 0] Loss: 6.6705, Acc: 0.2161\n",
      "[Epoch 12, Step 100] Loss: 6.8186, Acc: 0.1982\n",
      "[Epoch 12, Step 200] Loss: 6.7949, Acc: 0.2119\n",
      "[Epoch 12, Step 300] Loss: 6.7308, Acc: 0.2091\n",
      "Epoch 12 Completed - Avg Loss: 6.6833, Avg Acc: 0.2222\n",
      "Learning Rate: 0.000080\n",
      "[Epoch 13, Step 0] Loss: 6.5844, Acc: 0.2346\n",
      "[Epoch 13, Step 100] Loss: 6.5950, Acc: 0.2331\n",
      "[Epoch 13, Step 200] Loss: 6.7804, Acc: 0.2009\n",
      "[Epoch 13, Step 300] Loss: 6.5767, Acc: 0.2244\n",
      "Epoch 13 Completed - Avg Loss: 6.7115, Avg Acc: 0.2217\n",
      "Learning Rate: 0.000076\n",
      "[Epoch 14, Step 0] Loss: 6.7530, Acc: 0.2175\n",
      "[Epoch 14, Step 100] Loss: 6.8145, Acc: 0.2202\n",
      "[Epoch 14, Step 200] Loss: 6.6048, Acc: 0.2351\n",
      "[Epoch 14, Step 300] Loss: 6.7205, Acc: 0.2160\n",
      "Epoch 14 Completed - Avg Loss: 6.7293, Avg Acc: 0.2204\n",
      "Learning Rate: 0.000073\n",
      "[Epoch 15, Step 0] Loss: 6.7117, Acc: 0.2162\n",
      "[Epoch 15, Step 100] Loss: 6.7597, Acc: 0.2201\n",
      "[Epoch 15, Step 200] Loss: 6.7576, Acc: 0.2102\n",
      "[Epoch 15, Step 300] Loss: 6.6455, Acc: 0.2317\n",
      "Epoch 15 Completed - Avg Loss: 6.7500, Avg Acc: 0.2198\n",
      "Learning Rate: 0.000069\n",
      "[Epoch 16, Step 0] Loss: 6.7944, Acc: 0.2235\n",
      "[Epoch 16, Step 100] Loss: 6.7952, Acc: 0.2115\n",
      "[Epoch 16, Step 200] Loss: 6.8573, Acc: 0.2118\n",
      "[Epoch 16, Step 300] Loss: 6.8437, Acc: 0.2075\n",
      "Epoch 16 Completed - Avg Loss: 6.7763, Avg Acc: 0.2187\n",
      "Learning Rate: 0.000066\n",
      "[Epoch 17, Step 0] Loss: 6.7996, Acc: 0.2228\n",
      "[Epoch 17, Step 100] Loss: 6.7733, Acc: 0.2165\n",
      "[Epoch 17, Step 200] Loss: 6.8140, Acc: 0.2070\n",
      "[Epoch 17, Step 300] Loss: 6.8427, Acc: 0.1973\n",
      "Epoch 17 Completed - Avg Loss: 6.7995, Avg Acc: 0.2183\n",
      "Learning Rate: 0.000062\n",
      "[Epoch 18, Step 0] Loss: 6.7333, Acc: 0.2179\n",
      "[Epoch 18, Step 100] Loss: 6.9594, Acc: 0.2093\n",
      "[Epoch 18, Step 200] Loss: 6.8642, Acc: 0.2027\n",
      "[Epoch 18, Step 300] Loss: 6.8862, Acc: 0.2091\n",
      "Epoch 18 Completed - Avg Loss: 6.8189, Avg Acc: 0.2181\n",
      "Learning Rate: 0.000058\n",
      "[Epoch 19, Step 0] Loss: 7.0385, Acc: 0.1871\n",
      "[Epoch 19, Step 100] Loss: 6.8161, Acc: 0.2337\n",
      "[Epoch 19, Step 200] Loss: 6.8986, Acc: 0.2193\n",
      "[Epoch 19, Step 300] Loss: 6.6628, Acc: 0.2353\n",
      "Epoch 19 Completed - Avg Loss: 6.8433, Avg Acc: 0.2181\n",
      "Learning Rate: 0.000054\n",
      "[Epoch 20, Step 0] Loss: 6.9469, Acc: 0.2067\n",
      "[Epoch 20, Step 100] Loss: 6.8785, Acc: 0.2158\n",
      "[Epoch 20, Step 200] Loss: 6.8508, Acc: 0.2183\n",
      "[Epoch 20, Step 300] Loss: 6.9961, Acc: 0.2105\n",
      "Epoch 20 Completed - Avg Loss: 6.8669, Avg Acc: 0.2183\n",
      "Learning Rate: 0.000050\n",
      "[Epoch 21, Step 0] Loss: 6.8285, Acc: 0.2158\n",
      "[Epoch 21, Step 100] Loss: 6.8128, Acc: 0.2288\n",
      "[Epoch 21, Step 200] Loss: 6.8952, Acc: 0.2310\n",
      "[Epoch 21, Step 300] Loss: 6.8968, Acc: 0.2070\n",
      "Epoch 21 Completed - Avg Loss: 6.8889, Avg Acc: 0.2183\n",
      "Learning Rate: 0.000047\n",
      "[Epoch 22, Step 0] Loss: 6.8215, Acc: 0.2304\n",
      "[Epoch 22, Step 100] Loss: 6.9720, Acc: 0.2151\n",
      "[Epoch 22, Step 200] Loss: 6.9673, Acc: 0.2182\n",
      "[Epoch 22, Step 300] Loss: 6.8061, Acc: 0.2285\n",
      "Epoch 22 Completed - Avg Loss: 6.9134, Avg Acc: 0.2180\n",
      "Learning Rate: 0.000043\n",
      "[Epoch 23, Step 0] Loss: 6.9318, Acc: 0.2138\n",
      "[Epoch 23, Step 100] Loss: 6.8911, Acc: 0.2310\n",
      "[Epoch 23, Step 200] Loss: 7.0660, Acc: 0.1955\n",
      "[Epoch 23, Step 300] Loss: 6.9453, Acc: 0.2155\n",
      "Epoch 23 Completed - Avg Loss: 6.9382, Avg Acc: 0.2183\n",
      "Learning Rate: 0.000039\n",
      "[Epoch 24, Step 0] Loss: 6.9607, Acc: 0.2262\n",
      "[Epoch 24, Step 100] Loss: 7.0226, Acc: 0.2097\n",
      "[Epoch 24, Step 200] Loss: 6.9983, Acc: 0.2133\n",
      "[Epoch 24, Step 300] Loss: 7.0379, Acc: 0.2152\n",
      "Epoch 24 Completed - Avg Loss: 6.9625, Avg Acc: 0.2185\n",
      "Learning Rate: 0.000035\n",
      "[Epoch 25, Step 0] Loss: 7.0052, Acc: 0.2241\n",
      "[Epoch 25, Step 100] Loss: 6.9888, Acc: 0.2204\n",
      "[Epoch 25, Step 200] Loss: 7.1486, Acc: 0.2051\n",
      "[Epoch 25, Step 300] Loss: 7.0067, Acc: 0.2128\n",
      "Epoch 25 Completed - Avg Loss: 6.9889, Avg Acc: 0.2191\n",
      "Learning Rate: 0.000032\n",
      "[Epoch 26, Step 0] Loss: 6.9517, Acc: 0.2268\n",
      "[Epoch 26, Step 100] Loss: 7.1756, Acc: 0.2031\n",
      "[Epoch 26, Step 200] Loss: 6.9877, Acc: 0.2228\n",
      "[Epoch 26, Step 300] Loss: 7.0092, Acc: 0.2294\n",
      "Epoch 26 Completed - Avg Loss: 7.0200, Avg Acc: 0.2218\n",
      "Learning Rate: 0.000028\n",
      "[Epoch 27, Step 0] Loss: 6.9434, Acc: 0.2381\n",
      "[Epoch 27, Step 100] Loss: 7.1358, Acc: 0.2036\n",
      "[Epoch 27, Step 200] Loss: 6.9735, Acc: 0.2506\n",
      "[Epoch 27, Step 300] Loss: 7.1474, Acc: 0.2180\n",
      "Epoch 27 Completed - Avg Loss: 7.0493, Avg Acc: 0.2222\n",
      "Learning Rate: 0.000025\n",
      "[Epoch 28, Step 0] Loss: 7.0297, Acc: 0.2110\n",
      "[Epoch 28, Step 100] Loss: 6.9073, Acc: 0.2565\n",
      "[Epoch 28, Step 200] Loss: 7.0558, Acc: 0.2145\n",
      "[Epoch 28, Step 300] Loss: 7.0984, Acc: 0.2198\n",
      "Epoch 28 Completed - Avg Loss: 7.0810, Avg Acc: 0.2225\n",
      "Learning Rate: 0.000021\n",
      "[Epoch 29, Step 0] Loss: 7.1075, Acc: 0.2173\n",
      "[Epoch 29, Step 100] Loss: 7.0223, Acc: 0.2308\n",
      "[Epoch 29, Step 200] Loss: 7.1261, Acc: 0.2165\n",
      "[Epoch 29, Step 300] Loss: 7.1725, Acc: 0.2172\n",
      "Epoch 29 Completed - Avg Loss: 7.1132, Avg Acc: 0.2220\n",
      "Learning Rate: 0.000018\n",
      "[Epoch 30, Step 0] Loss: 7.1445, Acc: 0.2085\n",
      "[Epoch 30, Step 100] Loss: 7.1402, Acc: 0.2183\n",
      "[Epoch 30, Step 200] Loss: 7.1894, Acc: 0.2180\n",
      "[Epoch 30, Step 300] Loss: 7.0868, Acc: 0.2234\n",
      "Epoch 30 Completed - Avg Loss: 7.1421, Avg Acc: 0.2215\n",
      "Learning Rate: 0.000015\n",
      "[Epoch 31, Step 0] Loss: 7.1191, Acc: 0.2217\n",
      "[Epoch 31, Step 100] Loss: 7.2285, Acc: 0.2180\n",
      "[Epoch 31, Step 200] Loss: 7.1716, Acc: 0.2200\n",
      "[Epoch 31, Step 300] Loss: 7.1849, Acc: 0.2262\n",
      "Epoch 31 Completed - Avg Loss: 7.1678, Avg Acc: 0.2206\n",
      "Learning Rate: 0.000013\n",
      "[Epoch 32, Step 0] Loss: 7.1002, Acc: 0.2274\n",
      "[Epoch 32, Step 100] Loss: 7.0870, Acc: 0.2300\n",
      "[Epoch 32, Step 200] Loss: 7.0302, Acc: 0.2460\n",
      "[Epoch 32, Step 300] Loss: 7.1601, Acc: 0.2347\n",
      "Epoch 32 Completed - Avg Loss: 7.1883, Avg Acc: 0.2187\n",
      "Learning Rate: 0.000010\n",
      "[Epoch 33, Step 0] Loss: 7.1932, Acc: 0.2246\n",
      "[Epoch 33, Step 100] Loss: 7.2006, Acc: 0.2191\n",
      "[Epoch 33, Step 200] Loss: 7.1646, Acc: 0.2190\n",
      "[Epoch 33, Step 300] Loss: 7.1922, Acc: 0.2190\n",
      "Epoch 33 Completed - Avg Loss: 7.2037, Avg Acc: 0.2177\n",
      "Learning Rate: 0.000008\n",
      "[Epoch 34, Step 0] Loss: 7.1527, Acc: 0.2153\n",
      "[Epoch 34, Step 100] Loss: 7.2190, Acc: 0.2005\n",
      "[Epoch 34, Step 200] Loss: 7.2082, Acc: 0.2138\n",
      "[Epoch 34, Step 300] Loss: 7.2959, Acc: 0.2024\n",
      "Epoch 34 Completed - Avg Loss: 7.2152, Avg Acc: 0.2153\n",
      "Learning Rate: 0.000006\n",
      "[Epoch 35, Step 0] Loss: 7.1514, Acc: 0.2257\n",
      "[Epoch 35, Step 100] Loss: 7.3207, Acc: 0.2009\n",
      "[Epoch 35, Step 200] Loss: 7.2496, Acc: 0.2153\n",
      "[Epoch 35, Step 300] Loss: 7.1674, Acc: 0.2255\n",
      "Epoch 35 Completed - Avg Loss: 7.2248, Avg Acc: 0.2131\n",
      "Learning Rate: 0.000005\n",
      "[Epoch 36, Step 0] Loss: 7.1779, Acc: 0.2341\n",
      "[Epoch 36, Step 100] Loss: 7.1744, Acc: 0.2211\n",
      "[Epoch 36, Step 200] Loss: 7.0865, Acc: 0.2360\n",
      "[Epoch 36, Step 300] Loss: 7.1656, Acc: 0.2140\n",
      "Epoch 36 Completed - Avg Loss: 7.2317, Avg Acc: 0.2110\n",
      "Learning Rate: 0.000003\n",
      "[Epoch 37, Step 0] Loss: 7.3097, Acc: 0.1963\n",
      "[Epoch 37, Step 100] Loss: 7.0788, Acc: 0.2333\n",
      "[Epoch 37, Step 200] Loss: 7.1929, Acc: 0.2174\n",
      "[Epoch 37, Step 300] Loss: 7.3662, Acc: 0.1903\n",
      "Epoch 37 Completed - Avg Loss: 7.2362, Avg Acc: 0.2089\n",
      "Learning Rate: 0.000002\n",
      "[Epoch 38, Step 0] Loss: 7.1595, Acc: 0.2242\n",
      "[Epoch 38, Step 100] Loss: 7.1944, Acc: 0.2100\n",
      "[Epoch 38, Step 200] Loss: 7.1951, Acc: 0.2308\n",
      "[Epoch 38, Step 300] Loss: 7.1795, Acc: 0.1975\n",
      "Epoch 38 Completed - Avg Loss: 7.2396, Avg Acc: 0.2070\n",
      "Learning Rate: 0.000002\n",
      "[Epoch 39, Step 0] Loss: 7.3206, Acc: 0.1978\n",
      "[Epoch 39, Step 100] Loss: 7.3178, Acc: 0.2045\n",
      "[Epoch 39, Step 200] Loss: 7.3067, Acc: 0.1911\n",
      "[Epoch 39, Step 300] Loss: 7.3368, Acc: 0.2005\n",
      "Epoch 39 Completed - Avg Loss: 7.2408, Avg Acc: 0.2068\n",
      "Learning Rate: 0.000001\n",
      "[Epoch 40, Step 0] Loss: 7.2212, Acc: 0.2067\n",
      "[Epoch 40, Step 100] Loss: 7.2332, Acc: 0.2123\n",
      "[Epoch 40, Step 200] Loss: 7.3576, Acc: 0.1946\n",
      "[Epoch 40, Step 300] Loss: 7.3784, Acc: 0.1708\n",
      "Epoch 40 Completed - Avg Loss: 7.2424, Avg Acc: 0.2057\n",
      "Learning Rate: 0.000001\n",
      "CPU times: user 11min 13s, sys: 1.65 s, total: 11min 14s\n",
      "Wall time: 7min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 🔴 [변경] GPT-1 스타일 학습\n",
    "train_gpt1(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=40,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference_section",
   "metadata": {},
   "source": [
    "## **Step 7. 추론**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "generation_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, question, sp, device, max_len=50, temperature=0.8):\n",
    "    \"\"\"\n",
    "    GPT-1 스타일 응답 생성\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize question\n",
    "    q_tokens = sp.encode_as_ids(question)\n",
    "    input_ids = [sp.bos_id()] + q_tokens\n",
    "    \n",
    "    print(f\"입력: {question}\")\n",
    "    print(f\"토큰 ID: {input_ids}\")\n",
    "    \n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            # Prepare input\n",
    "            x = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits, _ = model(x)\n",
    "            \n",
    "            # Get next token logits\n",
    "            next_token_logits = logits[0, -1, :] / temperature\n",
    "            \n",
    "            # Sample from distribution\n",
    "            probs = F.softmax(next_token_logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "            \n",
    "            # Stop if EOS\n",
    "            if next_token == sp.eos_id():\n",
    "                break\n",
    "            \n",
    "            input_ids.append(next_token)\n",
    "    \n",
    "    # Decode response\n",
    "    answer_start = len([sp.bos_id()] + q_tokens)\n",
    "    answer_tokens = input_ids[answer_start:]\n",
    "    response = sp.decode_ids(answer_tokens)\n",
    "    \n",
    "    print(f\"출력: {response}\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_section",
   "metadata": {},
   "source": [
    "## **Step 8. 테스트**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "test_1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: 여행이나 갈까\n",
      "토큰 ID: [2, 438, 586, 1866]\n",
      "출력:  ⁇ 즐 필요한 화장품 평온 누구듯 나에게 스트레스가지만 ⁇ 됩니다 . 않고퍼 . . . 사람마다 대우 와서 가기로 목 않았으면 옳확졌율 기다리 충전하세요 .더라도말고 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' ⁇ 즐 필요한 화장품 평온 누구듯 나에게 스트레스가지만 ⁇ 됩니다 . 않고퍼 . . . 사람마다 대우 와서 가기로 목 않았으면 옳확졌율 기다리 충전하세요 .더라도말고 .'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(model, \"여행이나 갈까\", sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "test_2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: 짜장면 먹고싶네\n",
      "토큰 ID: [2, 4444, 360, 6935]\n",
      "출력: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(model, \"짜장면 먹고싶네\", sp, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "test_3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: 책 추천좀\n",
      "토큰 ID: [2, 1063, 748, 7088]\n",
      "출력:  ⁇  메뉴 ⁇  존중하고 정신차 섬유년 붙륜극이 준비를 신낚 잠팁아 ⁇ 헥 풀어 말고 가면 미친 나한테 거예요 회 울 멀리 건강하게페 치맛 ⁇  귀 레시피 있나봅니다 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' ⁇  메뉴 ⁇  존중하고 정신차 섬유년 붙륜극이 준비를 신낚 잠팁아 ⁇ 헥 풀어 말고 가면 미친 나한테 거예요 회 울 멀리 건강하게페 치맛 ⁇  귀 레시피 있나봅니다 .'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(model, \"책 추천좀\", sp, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bugfix_summary",
   "metadata": {},
   "source": [
    "## **변경 사항 최종 정리**\n",
    "\n",
    "### **🔴 주요 변경 사항**\n",
    "\n",
    "#### **1. 아키텍처 변경**\n",
    "- **기존**: Encoder-Decoder Transformer\n",
    "- **변경**: Decoder-only Transformer (GPT-1 방식)\n",
    "- **이유**: GPT-1은 언어 모델이므로 Decoder만 사용\n",
    "\n",
    "#### **2. 입력 형식 변경**\n",
    "- **기존**: 별도의 인코더/디코더 입력\n",
    "- **변경**: `[BOS] Question $ Answer [EOS]` 형식\n",
    "- **이유**: GPT-1의 task-specific input transformation\n",
    "\n",
    "#### **3. 학습 목표 변경**\n",
    "- **기존**: Sequence-to-sequence\n",
    "- **변경**: Next token prediction (Language Modeling)\n",
    "- **이유**: GPT-1의 핵심은 언어 모델 사전 학습\n",
    "\n",
    "#### **4. 모델 구성요소 변경**\n",
    "- **Position Embedding**: Sinusoidal → Learned (학습 가능)\n",
    "- **Activation Function**: ReLU → GELU\n",
    "- **Normalization**: Pre-norm → Post-norm (GPT-1 방식)\n",
    "\n",
    "#### **5. 학습 방식 변경**\n",
    "- **Optimizer**: Custom → Adam (GPT-1 설정)\n",
    "- **Learning Rate Schedule**: Linear warmup + cosine annealing\n",
    "- **Weight Initialization**: N(0, 0.02)\n",
    "\n",
    "### **성능 비교**\n",
    "이 구현은 GPT-1 논문의 핵심 개념을 적용하되, 계산 자원을 고려하여:\n",
    "- 레이어 수: 12 → 4\n",
    "- 모델 크기: 768 → 256\n",
    "- Pre-training 생략 (직접 fine-tuning)\n",
    "\n",
    "### **실제 GPT-1과의 차이**\n",
    "1. Pre-training 단계 생략 (BooksCorpus 등 대규모 데이터 필요)\n",
    "2. 모델 크기 축소 (원 논문: 117M 파라미터)\n",
    "3. 데이터셋 규모 차이\n",
    "\n",
    "### **향후 개선 방향**\n",
    "1. Pre-training 단계 추가 (더 많은 한국어 텍스트로)\n",
    "2. Auxiliary LM objective 추가 (Fine-tuning 시)\n",
    "3. 모델 크기 증가\n",
    "4. BPE dropout 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4ee5f-8ba1-4576-b042-1aaf1acfa2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
